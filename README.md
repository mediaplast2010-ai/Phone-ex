# app.py
# –û–Ω–ª–∞–π–Ω Phone Extractor –∑ –º–∞—Å–æ–≤–∏–º –≤–≤–µ–¥–µ–Ω–Ω—è–º —Å–∞–π—Ç—ñ–≤ | –£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞

import streamlit as st
import requests
from bs4 import BeautifulSoup
import re
from urllib.parse import urlparse
from time import sleep

# –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏
st.set_page_config(page_title="üìû Phone Extractor –û–Ω–ª–∞–π–Ω", layout="centered")

# –ó–∞–≥–æ–ª–æ–≤–æ–∫
st.title("üìû Phone Extractor")
st.markdown("–í–≤–µ–¥—ñ—Ç—å –æ–¥–∏–Ω –∞–±–æ –∫—ñ–ª—å–∫–∞ URL (–ø–æ –æ–¥–Ω–æ–º—É –Ω–∞ —Ä—è–¥–æ–∫) ‚Äî –∑–Ω–∞–π–¥–µ–º–æ —É—Å—ñ —Ç–µ–ª–µ—Ñ–æ–Ω–Ω—ñ –Ω–æ–º–µ—Ä–∏")

# –ü–æ–ª–µ –≤–≤–æ–¥—É (–±–∞–≥–∞—Ç–æ—Ä—è–¥–∫–æ–≤–µ)
urls_input = st.text_area(
    "–°–ø–∏—Å–æ–∫ —Å–∞–π—Ç—ñ–≤",
    placeholder="https://idcompass.com\nhttps://example.com",
    height=150
)

# –ö–Ω–æ–ø–∫–∞
if st.button("üîç –ó–Ω–∞–π—Ç–∏ —Ç–µ–ª–µ—Ñ–æ–Ω–∏"):
    if not urls_input.strip():
        st.warning("–ë—É–¥—å –ª–∞—Å–∫–∞, –≤–≤–µ–¥—ñ—Ç—å —Ö–æ—á–∞ –± –æ–¥–∏–Ω URL")
    else:
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ –Ω–∞ —Ä—è–¥–∫–∏ —Ç–∞ –æ—á–∏—â–∞—î–º–æ
        url_list = [url.strip() for url in urls_input.splitlines() if url.strip()]
        total_urls = len(url_list)

        st.info(f"–û–±—Ä–æ–±–ª—è—î–º–æ {total_urls} —Å–∞–π—Ç—ñ–≤...")

        all_phones = {}  # —Å–ª–æ–≤–Ω–∏–∫: —Å–∞–π—Ç ‚Üí —Ç–µ–ª–µ—Ñ–æ–Ω–∏
        failed_sites = []

        progress_bar = st.progress(0)
        status_text = st.empty()

        # –û–±—Ä–æ–±–∫–∞ –∫–æ–∂–Ω–æ–≥–æ —Å–∞–π—Ç—É
        for i, url in enumerate(url_list):
            status_text.text(f"–û–±—Ä–æ–±–ª—è—î–º–æ: {url}")
            progress_bar.progress((i + 1) / total_urls)

            if not url.startswith("http"):
                url = "https://" + url

            try:
                headers = {
                    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                }
                response = requests.get(url, headers=headers, timeout=15)
                response.raise_for_status()
                soup = BeautifulSoup(response.text, 'html.parser')
                text = soup.get_text()

                # –ü–æ—à—É–∫ —Ç–µ–ª–µ—Ñ–æ–Ω—ñ–≤
                phone_pattern = r'(\+\d{1,3}[-.\s]?)?\(?(\d{3})\)?[-.\s]?(\d{3})[-.\s]?(\d{4})'
                matches = re.findall(phone_pattern, text)

                phones = set()
                for match in matches:
                    phone = ''.join(match)
                    if f"+{phone}" in text or str(match[0]).startswith('+'):
                        phone = '+' + phone
                    phones.add(phone)

                phones = sorted(phones)

                domain = urlparse(url).netloc or "unknown"
                all_phones[domain] = phones

            except Exception as e:
                failed_sites.append(f"{url} ‚Äî –ø–æ–º–∏–ª–∫–∞: {str(e)}")

            sleep(0.5)  # –ª–µ–≥–∫–∞ –∑–∞—Ç—Ä–∏–º–∫–∞, —â–æ–± –Ω–µ –±–ª–æ–∫—É–≤–∞–ª–∏

        # –ü—ñ–¥—Å—É–º–æ–∫
        status_text.text("–ü–æ—à—É–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        progress_bar.progress(100)

        # –í–∏–≤—ñ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        if all_phones:
            st.success("‚úÖ –ü–æ—à—É–∫ –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ó–Ω–∞–π–¥–µ–Ω—ñ —Ç–µ–ª–µ—Ñ–æ–Ω–∏:")

            full_output = ""
            for domain, phones in all_phones.items():
                if phones:
                    st.markdown(f"### üåê `{domain}`")
                    for phone in phones:
                        st.code(phone)
                    full_output += f"{domain}\n" + "\n".join(phones) + "\n\n"
                else:
                    st.info(f"‚ÑπÔ∏è –ù–∞ `{domain}` —Ç–µ–ª–µ—Ñ–æ–Ω–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
                    full_output += f"{domain}\n(–Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ)\n\n"

            # –ö–Ω–æ–ø–∫–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
            st.download_button(
                label="‚¨áÔ∏è –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤—Å—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —è–∫ .txt",
                data=full_output.strip(),
                file_name="phone_extractor_results.txt",
                mime="text/plain"
            )
        else:
            st.warning("‚ùå –¢–µ–ª–µ—Ñ–æ–Ω–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –Ω–∞ –∂–æ–¥–Ω–æ–º—É —Å–∞–π—Ç—ñ.")

        if failed_sites:
            st.error("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ–±—Ä–æ–±–∏—Ç–∏:")
            for fail in failed_sites:
                st.markdown(f"- `{fail}`")

# –§—É—Ç–µ—Ä
st.markdown("---")
st.markdown(
    "üí° <small>–î–æ–¥–∞—Ç–æ–∫ –ø—Ä–∞—Ü—é—î –±–µ–∑ –∑–±–µ—Ä—ñ–≥–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö. –ù–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ –¥–ª—è —Å–ø–∞–º—É.</small>",
    unsafe_allow_html=True
)
